{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자동차 번호판 인식 with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 호출\n",
    "pytesseract : 글씨를 읽어내는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'   #기기에 설치된 소프트웨어적인 문제로 인한 임시조치\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "plt.style.use('dark_background')\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\rkdal/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-11-24 Python-3.11.10 torch-2.4.1 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully. Shape: (168, 533, 3)\n",
      "Saved cropped plate image to: .\\plate.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rkdal/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- 특정 folder 내에 있는 \"가장 최근에 생성된\" 파일을 리턴하는 방법 \n",
    "\"\"\"\n",
    "folder_path = 'runs/detect/result/crops/0/'\n",
    "\n",
    "# YOLOv5 모델 로드\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', 'best.pt')  #yolov5s, yolov5m, yolov5l, yolov5x, custom\n",
    "\n",
    "\n",
    "# each_file_path_and_gen_time: 각 file의 경로와, 생성 시간을 저장함\n",
    "each_file_path_and_gen_time = []\n",
    "for each_file_name in os.listdir(folder_path):\n",
    "    # getctime: 입력받은 경로에 대한 생성 시간을 리턴\n",
    "    each_file_path = folder_path + each_file_name\n",
    "    each_file_gen_time = os.path.getctime(each_file_path)\n",
    "    each_file_path_and_gen_time.append(\n",
    "        (each_file_path, each_file_gen_time)\n",
    "    )\n",
    "\n",
    "# 가장 생성시각이 큰(가장 최근인) 파일을 리턴 \n",
    "most_recent_file = max(each_file_path_and_gen_time, key=lambda x: x[1])[0]\n",
    "# 이미지 불러오기\n",
    "img = cv2.imread(most_recent_file)\n",
    "\n",
    "# 이미지 확인\n",
    "if img is None:\n",
    "    print(\"Image not found or invalid path.\")\n",
    "else:\n",
    "    print(f\"Image loaded successfully. Shape: {img.shape}\")\n",
    "\n",
    "results = model(img)\n",
    "\n",
    "detections = results.xyxy[0]  # 탐지된 객체의 좌표\n",
    "for i, (*box, conf, cls) in enumerate(detections):  # 좌표, 신뢰도, 클래스\n",
    "    x1, y1, x2, y2 = map(int, box)  # 바운딩 박스 좌표\n",
    "    cropped_plate = img[y1:y2, x1:x2]  # 차량번호판 영역 자르기\n",
    "\n",
    "output_path = os.path.join('.', f'plate.jpg')\n",
    "cv2.imwrite(output_path, cropped_plate)\n",
    "print(f\"Saved cropped plate image to: {output_path}\")\n",
    "\n",
    "img = output_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert Image to Grayscale\n",
    "\n",
    "* BGR -> GRAY 변환법\n",
    "1. BGR2GRAY\n",
    "```python\n",
    "cv2.cvtColor(이미지, cv2.COLOR_BGR2GRAY)\n",
    "```\n",
    "2. hsv\n",
    "```python\n",
    "hsv = cv2.cvtColor(img_ori, cv2.COLOR_BGR2HSV)\n",
    "gray = hsv[:, :, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_gray(image, image_show=True):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if image_show:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.imshow(gray, cmap='gray')\n",
    "        plt.title('흑백화')\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# 원본 이미지(BRG)를 gray 버전으로 변경\u001b[39;00m\n\u001b[0;32m      3\u001b[0m (thresh, blackAndWhiteImage) \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(gray, \u001b[38;5;241m127\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY) \u001b[38;5;66;03m#gray 이미지를 흑백으로 변경\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    # 원본 이미지(BRG)를 gray 버전으로 변경\n",
    "\n",
    "(thresh, blackAndWhiteImage) = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY) #gray 이미지를 흑백으로 변경\n",
    " \n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adaptive Thresholding\n",
    "\n",
    "* GaussianBlur  \n",
    ": 노이즈를 줄이기 위해  \n",
    "  \n",
    "* adaptiveThreshold  \n",
    ": threshold 보다 낮은 값 = 0, 높은 값 : 255  \n",
    ": 이미지 구분을 쉽게 만들어줌  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8b1b29690>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_blurred = cv2.GaussianBlur(gray, ksize=(5, 5), sigmaX=0)\n",
    "\n",
    "img_blur_thresh = cv2.adaptiveThreshold(\n",
    "    img_blurred,\n",
    "    maxValue=255.0,\n",
    "    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    thresholdType=cv2.THRESH_BINARY_INV,\n",
    "    blockSize=19,\n",
    "    C=11\n",
    ")\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.imshow(img_blur_thresh, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find Contours\n",
    "\n",
    "이미지에서 윤곽선 찾기  \n",
    "\n",
    "※ 변경사항  \n",
    ": findContours() 함수의 리턴 값이 3개라고 많은 자료들이 말함 -> 2개로 바뀐듯함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8b1ac2050>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours, _ = cv2.findContours(\n",
    "    img_blur_thresh,\n",
    "    mode=cv2.RETR_LIST,\n",
    "    method=cv2.CHAIN_APPROX_SIMPLE\n",
    ")\n",
    "\n",
    "temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "cv2.drawContours(temp_result, contours=contours, contourIdx=-1, color=(255,255,255))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(temp_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8b1b4a910>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "contours_dict = []\n",
    "\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(temp_result, pt1=(x,y), pt2=(x+w, y+h), color=(255,255,255), thickness=2)\n",
    "    \n",
    "    contours_dict.append({\n",
    "        'contour': contour,\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'w': w,\n",
    "        'h': h,\n",
    "        'cx': x + (w / 2),\n",
    "        'cy': y + (h / 2)\n",
    "    })\n",
    "    \n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(temp_result, cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Select Candidates by Char Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8b1b6da10>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_AREA = 80\n",
    "MIN_WIDTH, MIN_HEIGHT=2, 8\n",
    "MIN_RATIO, MAX_RATIO = 0.2, 1.0\n",
    "\n",
    "possible_contours = []\n",
    "\n",
    "cnt = 0\n",
    "for d in contours_dict:\n",
    "    area = d['w'] * d['h']\n",
    "    ratio = d['w'] / d['h']\n",
    "    \n",
    "    if area > MIN_AREA \\\n",
    "    and d['w'] > MIN_WIDTH and d['h'] > MIN_HEIGHT \\\n",
    "    and MIN_RATIO < ratio < MAX_RATIO:\n",
    "        d['idx'] = cnt\n",
    "        cnt += 1\n",
    "        possible_contours.append(d)\n",
    "\n",
    "temp_result = np.zeros((height, width, channel), dtype = np.uint8)\n",
    "\n",
    "for d in possible_contours:\n",
    "    cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255, 255, 255), thickness=2)\n",
    "    \n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(temp_result, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Select Candidates by Arrangement of Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8b1bddb10>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_DIAG_MULTIPLYER = 5\n",
    "MAX_ANGLE_DIFF = 12.0\n",
    "MAX_AREA_DIFF = 0.5\n",
    "MAX_WIDTH_DIFF = 0.8\n",
    "MAX_HEIGHT_DIFF = 0.2\n",
    "MIN_N_MATCHED = 3\n",
    "\n",
    "def find_chars(contour_list):\n",
    "    matched_result_idx = []\n",
    "    \n",
    "    for d1 in contour_list:\n",
    "        matched_contours_idx = []\n",
    "        for d2 in contour_list:\n",
    "            if d1['idx'] == d2['idx']:\n",
    "                continue\n",
    "                \n",
    "            dx = abs(d1['cx'] - d2['cx'])\n",
    "            dy = abs(d1['cy'] - d2['cy'])\n",
    "            \n",
    "            diagonal_length1 = np.sqrt(d1['w'] ** 2 + d1['h'] ** 2)\n",
    "            \n",
    "            distance = np.linalg.norm(np.array([d1['cx'], d1['cy']]) - np.array([d2['cx'], d2['cy']]))\n",
    "            if dx == 0:\n",
    "                angle_diff = 90\n",
    "            else:\n",
    "                angle_diff = np.degrees(np.arctan(dy / dx))\n",
    "            area_diff = abs(d1['w'] * d1['h'] - d2['w'] * d2['h']) / (d1['w'] * d1['h'])\n",
    "            width_diff = abs(d1['w'] - d2['w']) / d1['w']\n",
    "            height_diff = abs(d1['h'] - d2['h']) / d1['h']\n",
    "            \n",
    "            if distance < diagonal_length1 * MAX_DIAG_MULTIPLYER \\\n",
    "            and angle_diff < MAX_ANGLE_DIFF and area_diff < MAX_AREA_DIFF \\\n",
    "            and width_diff < MAX_WIDTH_DIFF and height_diff < MAX_HEIGHT_DIFF:\n",
    "                matched_contours_idx.append(d2['idx'])\n",
    "                \n",
    "        matched_contours_idx.append(d1['idx'])\n",
    "        \n",
    "        if len(matched_contours_idx) < MIN_N_MATCHED:\n",
    "            continue\n",
    "            \n",
    "        matched_result_idx.append(matched_contours_idx)\n",
    "        \n",
    "        unmatched_contour_idx = []\n",
    "        for d4 in contour_list:\n",
    "            if d4['idx'] not in matched_contours_idx:\n",
    "                unmatched_contour_idx.append(d4['idx'])\n",
    "        \n",
    "        unmatched_contour = np.take(possible_contours, unmatched_contour_idx)\n",
    "        \n",
    "        recursive_contour_list = find_chars(unmatched_contour)\n",
    "        \n",
    "        for idx in recursive_contour_list:\n",
    "            matched_result_idx.append(idx)\n",
    "            \n",
    "        break\n",
    "        \n",
    "    return matched_result_idx\n",
    "\n",
    "result_idx = find_chars(possible_contours)\n",
    "\n",
    "matched_result = []\n",
    "for idx_list in result_idx:\n",
    "    matched_result.append(np.take(possible_contours, idx_list))\n",
    "    \n",
    "temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "for r in matched_result:\n",
    "    for d in r:\n",
    "        cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255,255,255), thickness=2)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(temp_result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Rotate Plate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLATE_WIDTH_PADDING = 1.3 # 1.3\n",
    "PLATE_HEIGHT_PADDING = 1.5 # 1.5\n",
    "MIN_PLATE_RATIO = 3\n",
    "MAX_PLATE_RATIO = 10\n",
    "\n",
    "plate_imgs = []\n",
    "plate_infos = []\n",
    "\n",
    "for i, matched_chars in enumerate(matched_result):\n",
    "    sorted_chars = sorted(matched_chars, key=lambda x: x['cx'])\n",
    "\n",
    "    plate_cx = (sorted_chars[0]['cx'] + sorted_chars[-1]['cx']) / 2\n",
    "    plate_cy = (sorted_chars[0]['cy'] + sorted_chars[-1]['cy']) / 2\n",
    "    \n",
    "    plate_width = (sorted_chars[-1]['x'] + sorted_chars[-1]['w'] - sorted_chars[0]['x']) * PLATE_WIDTH_PADDING\n",
    "    \n",
    "    sum_height = 0\n",
    "    for d in sorted_chars:\n",
    "        sum_height += d['h']\n",
    "\n",
    "    plate_height = int(sum_height / len(sorted_chars) * PLATE_HEIGHT_PADDING)\n",
    "    \n",
    "    triangle_height = sorted_chars[-1]['cy'] - sorted_chars[0]['cy']\n",
    "    triangle_hypotenus = np.linalg.norm(\n",
    "        np.array([sorted_chars[0]['cx'], sorted_chars[0]['cy']]) - \n",
    "        np.array([sorted_chars[-1]['cx'], sorted_chars[-1]['cy']])\n",
    "    )\n",
    "    \n",
    "    angle = np.degrees(np.arcsin(triangle_height / triangle_hypotenus))\n",
    "    \n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center=(plate_cx, plate_cy), angle=angle, scale=1.0)\n",
    "    \n",
    "    img_rotated = cv2.warpAffine(img_blur_thresh, M=rotation_matrix, dsize=(width, height))\n",
    "    \n",
    "    img_cropped = cv2.getRectSubPix(\n",
    "        img_rotated, \n",
    "        patchSize=(int(plate_width), int(plate_height)), \n",
    "        center=(int(plate_cx), int(plate_cy))\n",
    "    )\n",
    "    \n",
    "    if img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO or img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO > MAX_PLATE_RATIO:\n",
    "        continue\n",
    "    \n",
    "    plate_imgs.append(img_cropped)\n",
    "    plate_infos.append({\n",
    "        'x': int(plate_cx - plate_width / 2),\n",
    "        'y': int(plate_cy - plate_height / 2),\n",
    "        'w': int(plate_width),\n",
    "        'h': int(plate_height)\n",
    "    })\n",
    "    \n",
    "    plt.subplot(len(matched_result), 1, i+1)\n",
    "    plt.imshow(img_cropped, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Another Thresholding\n",
    "\n",
    "## 11. Find Chars   확인 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아소7652\n"
     ]
    }
   ],
   "source": [
    "longest_idx, longest_text = -1, 0\n",
    "plate_chars = []\n",
    "\n",
    "for i, plate_img in enumerate(plate_imgs):\n",
    "    plate_img = cv2.resize(plate_img, dsize=(0, 0), fx=1.6, fy=1.6)\n",
    "    _, plate_img = cv2.threshold(plate_img, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    \n",
    "    # find contours again (same as above)\n",
    "    contours, _ = cv2.findContours(plate_img, mode=cv2.RETR_LIST, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    plate_min_x, plate_min_y = plate_img.shape[1], plate_img.shape[0]\n",
    "    plate_max_x, plate_max_y = 0, 0\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        area = w * h\n",
    "        ratio = w / h\n",
    "\n",
    "        if area > MIN_AREA \\\n",
    "        and w > MIN_WIDTH and h > MIN_HEIGHT \\\n",
    "        and MIN_RATIO < ratio < MAX_RATIO:\n",
    "            if x < plate_min_x:\n",
    "                plate_min_x = x\n",
    "            if y < plate_min_y:\n",
    "                plate_min_y = y\n",
    "            if x + w > plate_max_x:\n",
    "                plate_max_x = x + w\n",
    "            if y + h > plate_max_y:\n",
    "                plate_max_y = y + h\n",
    "                \n",
    "    img_result = plate_img[plate_min_y:plate_max_y, plate_min_x:plate_max_x]\n",
    "    \n",
    "    img_result = cv2.GaussianBlur(img_result, ksize=(3, 3), sigmaX=0)\n",
    "    _, img_result = cv2.threshold(img_result, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    img_result = cv2.copyMakeBorder(img_result, top=10, bottom=10, left=10, right=10, borderType=cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "    \n",
    "    chars = pytesseract.image_to_string(img_result, lang='kornum+kor', config='--psm 6 preserve_interword_spaces')\n",
    "    #chars = pytesseract.image_to_string(img_result, lang='kornum+kor', config='--psm 7 --oem 3')\n",
    "    \n",
    "    result_chars = ''\n",
    "    has_digit = False\n",
    "    for c in chars:\n",
    "        if ord('가') <= ord(c) <= ord('힣') or c.isdigit():\n",
    "            if c.isdigit():\n",
    "                has_digit = True\n",
    "            result_chars += c\n",
    "    \n",
    "    print(result_chars)\n",
    "    plate_chars.append(result_chars)\n",
    "\n",
    "    if has_digit and len(result_chars) > longest_text:\n",
    "        longest_idx = i\n",
    "\n",
    "    plt.subplot(len(plate_imgs), 1, i+1)\n",
    "    plt.imshow(img_result, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인식이 되지 않았습니다 재진입하십시오\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rkdal\\AppData\\Local\\Temp\\ipykernel_37688\\3567969644.py:19: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(12, 10))\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    info = plate_infos[longest_idx]\n",
    "    chars = plate_chars[longest_idx]\n",
    "    if ord('가') <= ord(chars[2]) <= ord('힣') and len(chars) == 7:\n",
    "        print(chars)\n",
    "        excel()\n",
    "    elif ord('가') <= ord(chars[3]) <= ord('힣') and len(chars) == 8:\n",
    "        print(chars)\n",
    "        excel()\n",
    "    else :\n",
    "        print('인식이 되지 않았습니다 재진입하십시오')\n",
    "\n",
    "    img_out = img_ori.copy()\n",
    "\n",
    "    cv2.rectangle(img_out, pt1=(info['x'], info['y']), pt2=(info['x']+info['w'], info['y']+info['h']), color=(255,0,0), thickness=2)\n",
    "\n",
    "    cv2.imwrite(chars + '.jpg', img_out)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img_out)\n",
    "except :\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pd.read_excel('plates.xlsx', sheet_name='Sheet1')\\nrow_list = []\\n\\ndf.loc[len(df)] = [chars]\\n# Excel 파일로 저장\\ndf.to_excel('plates.xlsx', index=False, sheet_name='Sheet1')\\n\\ndf.info\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df = pd.read_excel('plates.xlsx', sheet_name='Sheet1')\n",
    "row_list = []\n",
    "\n",
    "df.loc[len(df)] = [chars]\n",
    "# Excel 파일로 저장\n",
    "df.to_excel('plates.xlsx', index=False, sheet_name='Sheet1')\n",
    "\n",
    "df.info\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
